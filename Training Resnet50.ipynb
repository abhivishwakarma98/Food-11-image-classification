{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "HD-jaO82-htG",
    "outputId": "a14b37b4-1db7-4cce-bb58-6c6da8cf5c9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Importing neccessary packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "y8BzythP-qxQ",
    "outputId": "e2b01cd5-0f6e-49d5-89b3-18c85988c606"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.config',\n",
       " 'validation',\n",
       " 'drive',\n",
       " 'food11.zip',\n",
       " 'kaggle.json',\n",
       " 'evaluation',\n",
       " 'training',\n",
       " 'sample_data']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WISDbb5L-3e3"
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "The dataset is seperated into 3 folders: training, validation and evaluation.\n",
    "The images are named by convention as: {class_id}-{image_id}.jpg. Create subfolders inside training and validation for ImageDataGenerator to recognize classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GyrxQvSP-zOj"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BXphf7RzAC5l"
   },
   "outputs": [],
   "source": [
    "# Data augmentation for regularization and adding some extra training samples\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n",
    "    rescale=1.0/255.0,\n",
    "    horizontal_flip=True, \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    rotation_range=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-QWGC16AQ_-"
   },
   "outputs": [],
   "source": [
    "TARGET_DIM = 224\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Nhp1Xa4GAUmV",
    "outputId": "f268ff69-81ac-4482-aa9d-819d90c6a088"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9866 images belonging to 11 classes.\n",
      "Found 3430 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(\n",
    "    directory='./training/', \n",
    "    target_size=(TARGET_DIM, TARGET_DIM),\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    directory='./validation/',\n",
    "    target_size=(TARGET_DIM, TARGET_DIM),\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nyajl22tAXC-"
   },
   "outputs": [],
   "source": [
    "# Lets try the Resnet50 architecture\n",
    "\n",
    "base_model = tf.keras.applications.resnet50.ResNet50(\n",
    "    include_top=False, \n",
    "    weights='imagenet', \n",
    "    input_shape=(TARGET_DIM, TARGET_DIM, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "p3Tbj29fAZ9G",
    "outputId": "249f8676-d35d-4fa6-b315-4236bec2bfa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QISfc7r2AdC8",
    "outputId": "36c4d0d7-e612-41b3-dc47-d31bc8ef64a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers in resnet50: 175\n"
     ]
    }
   ],
   "source": [
    "print('Layers in resnet50: ' + str(len(base_model.layers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0DqbXDYROZMt",
    "outputId": "f609798d-d316-4c4d-ca24-2561de97f68f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conv5_block2_out'"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers[-11].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-txynW7AAglt"
   },
   "outputs": [],
   "source": [
    "preds = base_model.output\n",
    "preds = tf.keras.layers.GlobalAveragePooling2D()(preds)\n",
    "preds = tf.keras.layers.Dense(512, activation=tf.nn.relu)(preds)\n",
    "preds = tf.keras.layers.Dropout(0.5)(preds)\n",
    "preds = tf.keras.layers.Dense(256, activation=tf.nn.relu)(preds)\n",
    "preds = tf.keras.layers.Dropout(0.3)(preds)\n",
    "preds = tf.keras.layers.Dense(128, activation=tf.nn.relu)(preds)\n",
    "preds = tf.keras.layers.Dense(NUM_CLASSES, activation=tf.nn.softmax)(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z93r3vXPAl6-"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model(base_model.input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2xP0h_l4AnmY",
    "outputId": "f110b4a5-76b4-4b26-eec3-befbcf99b34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           1419        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 24,802,443\n",
      "Trainable params: 24,749,323\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "plibI0OlPF3I",
    "outputId": "29ff37aa-4e73-4924-86a1-53b76a2070cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'global_average_pooling2d'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-7].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JeG3d0KCApSN"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqgLC47yAz4M"
   },
   "outputs": [],
   "source": [
    "# Create directory in drive for storing model\n",
    "!mkdir drive/My\\ Drive/food_11_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l5qVM0phAsK0"
   },
   "outputs": [],
   "source": [
    "# Lets define checkpoint for model saving\n",
    "filepath=\"./drive/My Drive/food_11_weights/resnet50-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QnET3wBCBG-S"
   },
   "outputs": [],
   "source": [
    "# Freeze mobilenet layers and train only newly added layers\n",
    "\n",
    "for layers in model.layers[:-7]:\n",
    "    layers.trainable = False\n",
    "\n",
    "for layers in model.layers[-7:]:\n",
    "    layers.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqVBDZEdBJH-"
   },
   "outputs": [],
   "source": [
    "# Lets stop training when model acheives desired accuracy\n",
    "\n",
    "class ModelCallback(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        # Check if validation accuracy is above 90% then stop training\n",
    "        if logs['acc'] >= 0.95:\n",
    "            print('Model reached its target')\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "model_callback = ModelCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tvlhQTlaBNsX",
    "outputId": "d7868570-7e80-4544-9d5f-7d2021f2034e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-11470dcc446c>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 2.2650 - acc: 0.2081\n",
      "Epoch 00001: val_acc improved from -inf to 0.14574, saving model to ./drive/My Drive/food_11_weights/resnet50-01-0.15.hdf5\n",
      "616/616 [==============================] - 237s 385ms/step - loss: 2.2650 - acc: 0.2081 - val_loss: 3.7166 - val_acc: 0.1457\n",
      "Epoch 2/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 2.1152 - acc: 0.2639\n",
      "Epoch 00002: val_acc improved from 0.14574 to 0.16501, saving model to ./drive/My Drive/food_11_weights/resnet50-02-0.17.hdf5\n",
      "616/616 [==============================] - 237s 384ms/step - loss: 2.1152 - acc: 0.2639 - val_loss: 23.2713 - val_acc: 0.1650\n",
      "Epoch 3/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 2.0011 - acc: 0.3013\n",
      "Epoch 00003: val_acc improved from 0.16501 to 0.27862, saving model to ./drive/My Drive/food_11_weights/resnet50-03-0.28.hdf5\n",
      "616/616 [==============================] - 236s 384ms/step - loss: 2.0011 - acc: 0.3013 - val_loss: 2.2051 - val_acc: 0.2786\n",
      "Epoch 4/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.8938 - acc: 0.3397\n",
      "Epoch 00004: val_acc improved from 0.27862 to 0.30929, saving model to ./drive/My Drive/food_11_weights/resnet50-04-0.31.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.8938 - acc: 0.3397 - val_loss: 2.0667 - val_acc: 0.3093\n",
      "Epoch 5/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.8068 - acc: 0.3726\n",
      "Epoch 00005: val_acc improved from 0.30929 to 0.39807, saving model to ./drive/My Drive/food_11_weights/resnet50-05-0.40.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.8068 - acc: 0.3726 - val_loss: 1.7465 - val_acc: 0.3981\n",
      "Epoch 6/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.7284 - acc: 0.3962\n",
      "Epoch 00006: val_acc did not improve from 0.39807\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 1.7284 - acc: 0.3962 - val_loss: 1.8991 - val_acc: 0.3756\n",
      "Epoch 7/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.6462 - acc: 0.4227\n",
      "Epoch 00007: val_acc improved from 0.39807 to 0.44539, saving model to ./drive/My Drive/food_11_weights/resnet50-07-0.45.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.6462 - acc: 0.4227 - val_loss: 1.6162 - val_acc: 0.4454\n",
      "Epoch 8/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.5698 - acc: 0.4581\n",
      "Epoch 00008: val_acc did not improve from 0.44539\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 1.5698 - acc: 0.4581 - val_loss: 1.8757 - val_acc: 0.4098\n",
      "Epoch 9/50\n",
      "  7/616 [..............................] - ETA: 2:41 - loss: 1.6387 - acc: 0.4375WARNING:tensorflow:From <ipython-input-31-11470dcc446c>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 2.2650 - acc: 0.2081\n",
      "Epoch 00001: val_acc improved from -inf to 0.14574, saving model to ./drive/My Drive/food_11_weights/resnet50-01-0.15.hdf5\n",
      "616/616 [==============================] - 237s 385ms/step - loss: 2.2650 - acc: 0.2081 - val_loss: 3.7166 - val_acc: 0.1457\n",
      "Epoch 2/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 2.1152 - acc: 0.2639\n",
      "Epoch 00002: val_acc improved from 0.14574 to 0.16501, saving model to ./drive/My Drive/food_11_weights/resnet50-02-0.17.hdf5\n",
      "616/616 [==============================] - 237s 384ms/step - loss: 2.1152 - acc: 0.2639 - val_loss: 23.2713 - val_acc: 0.1650\n",
      "Epoch 3/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 2.0011 - acc: 0.3013\n",
      "Epoch 00003: val_acc improved from 0.16501 to 0.27862, saving model to ./drive/My Drive/food_11_weights/resnet50-03-0.28.hdf5\n",
      "616/616 [==============================] - 236s 384ms/step - loss: 2.0011 - acc: 0.3013 - val_loss: 2.2051 - val_acc: 0.2786\n",
      "Epoch 4/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.8938 - acc: 0.3397\n",
      "Epoch 00004: val_acc improved from 0.27862 to 0.30929, saving model to ./drive/My Drive/food_11_weights/resnet50-04-0.31.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.8938 - acc: 0.3397 - val_loss: 2.0667 - val_acc: 0.3093\n",
      "Epoch 5/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.8068 - acc: 0.3726\n",
      "Epoch 00005: val_acc improved from 0.30929 to 0.39807, saving model to ./drive/My Drive/food_11_weights/resnet50-05-0.40.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.8068 - acc: 0.3726 - val_loss: 1.7465 - val_acc: 0.3981\n",
      "Epoch 6/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.7284 - acc: 0.3962\n",
      "Epoch 00006: val_acc did not improve from 0.39807\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 1.7284 - acc: 0.3962 - val_loss: 1.8991 - val_acc: 0.3756\n",
      "Epoch 7/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.6462 - acc: 0.4227\n",
      "Epoch 00007: val_acc improved from 0.39807 to 0.44539, saving model to ./drive/My Drive/food_11_weights/resnet50-07-0.45.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.6462 - acc: 0.4227 - val_loss: 1.6162 - val_acc: 0.4454\n",
      "Epoch 8/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.5698 - acc: 0.4581\n",
      "Epoch 00008: val_acc did not improve from 0.44539\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 1.5698 - acc: 0.4581 - val_loss: 1.8757 - val_acc: 0.4098\n",
      "Epoch 9/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.5021 - acc: 0.4796\n",
      "Epoch 00009: val_acc improved from 0.44539 to 0.51285, saving model to ./drive/My Drive/food_11_weights/resnet50-09-0.51.hdf5\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.44539 to 0.51285, saving model to ./drive/My Drive/food_11_weights/resnet50-09-0.51.hdf5\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 1.5021 - acc: 0.4796 - val_loss: 1.4311 - val_acc: 0.5129\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 1.5021 - acc: 0.4796 - val_loss: 1.4311 - val_acc: 0.5129\n",
      "Epoch 10/50\n",
      "Epoch 10/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.4499 - acc: 0.5022\n",
      "Epoch 00010: val_acc did not improve from 0.51285\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 1.4499 - acc: 0.5022 - val_loss: 1.5946 - val_acc: 0.4521\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.51285\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 1.4499 - acc: 0.5022 - val_loss: 1.5946 - val_acc: 0.4521\n",
      "Epoch 11/50\n",
      "Epoch 11/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.3922 - acc: 0.5247\n",
      "Epoch 00011: val_acc did not improve from 0.51285\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 1.3922 - acc: 0.5247 - val_loss: 1.4849 - val_acc: 0.4877\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.51285\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 1.3922 - acc: 0.5247 - val_loss: 1.4849 - val_acc: 0.4877\n",
      "Epoch 12/50\n",
      "Epoch 12/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.3238 - acc: 0.5522\n",
      "Epoch 00012: val_acc did not improve from 0.51285\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 1.3238 - acc: 0.5522 - val_loss: 1.9274 - val_acc: 0.4068\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.51285\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 1.3238 - acc: 0.5522 - val_loss: 1.9274 - val_acc: 0.4068\n",
      "Epoch 13/50\n",
      "Epoch 13/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.2639 - acc: 0.5735\n",
      "Epoch 00013: val_acc improved from 0.51285 to 0.56717, saving model to ./drive/My Drive/food_11_weights/resnet50-13-0.57.hdf5\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.51285 to 0.56717, saving model to ./drive/My Drive/food_11_weights/resnet50-13-0.57.hdf5\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 1.2639 - acc: 0.5735 - val_loss: 1.3094 - val_acc: 0.5672\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 1.2639 - acc: 0.5735 - val_loss: 1.3094 - val_acc: 0.5672\n",
      "Epoch 14/50\n",
      "Epoch 14/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.1991 - acc: 0.5930\n",
      "Epoch 00014: val_acc improved from 0.56717 to 0.59229, saving model to ./drive/My Drive/food_11_weights/resnet50-14-0.59.hdf5\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.56717 to 0.59229, saving model to ./drive/My Drive/food_11_weights/resnet50-14-0.59.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.1991 - acc: 0.5930 - val_loss: 1.2639 - val_acc: 0.5923\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.1991 - acc: 0.5930 - val_loss: 1.2639 - val_acc: 0.5923\n",
      "Epoch 15/50\n",
      "Epoch 15/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.1546 - acc: 0.6154\n",
      "Epoch 00015: val_acc did not improve from 0.59229\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 1.1546 - acc: 0.6154 - val_loss: 1.3824 - val_acc: 0.5526\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.59229\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 1.1546 - acc: 0.6154 - val_loss: 1.3824 - val_acc: 0.5526\n",
      "Epoch 16/50\n",
      "Epoch 16/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.1095 - acc: 0.6381\n",
      "Epoch 00016: val_acc improved from 0.59229 to 0.63464, saving model to ./drive/My Drive/food_11_weights/resnet50-16-0.63.hdf5\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.59229 to 0.63464, saving model to ./drive/My Drive/food_11_weights/resnet50-16-0.63.hdf5\n",
      "616/616 [==============================] - 234s 381ms/step - loss: 1.1095 - acc: 0.6381 - val_loss: 1.1175 - val_acc: 0.6346\n",
      "616/616 [==============================] - 234s 381ms/step - loss: 1.1095 - acc: 0.6381 - val_loss: 1.1175 - val_acc: 0.6346\n",
      "Epoch 17/50\n",
      "Epoch 17/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.0542 - acc: 0.6518\n",
      "Epoch 00017: val_acc improved from 0.63464 to 0.64749, saving model to ./drive/My Drive/food_11_weights/resnet50-17-0.65.hdf5\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.63464 to 0.64749, saving model to ./drive/My Drive/food_11_weights/resnet50-17-0.65.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.0542 - acc: 0.6518 - val_loss: 1.1210 - val_acc: 0.6475\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 1.0542 - acc: 0.6518 - val_loss: 1.1210 - val_acc: 0.6475\n",
      "Epoch 18/50\n",
      "Epoch 18/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 1.0316 - acc: 0.6662\n",
      "Epoch 00018: val_acc did not improve from 0.64749\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 1.0316 - acc: 0.6662 - val_loss: 1.1252 - val_acc: 0.6303\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.64749\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 1.0316 - acc: 0.6662 - val_loss: 1.1252 - val_acc: 0.6303\n",
      "Epoch 19/50\n",
      "Epoch 19/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.9958 - acc: 0.6668\n",
      "Epoch 00019: val_acc did not improve from 0.64749\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.9958 - acc: 0.6668 - val_loss: 1.4173 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.64749\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.9958 - acc: 0.6668 - val_loss: 1.4173 - val_acc: 0.5850\n",
      "Epoch 20/50\n",
      "Epoch 20/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.9705 - acc: 0.6803\n",
      "Epoch 00020: val_acc improved from 0.64749 to 0.65567, saving model to ./drive/My Drive/food_11_weights/resnet50-20-0.66.hdf5\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.64749 to 0.65567, saving model to ./drive/My Drive/food_11_weights/resnet50-20-0.66.hdf5\n",
      "616/616 [==============================] - 237s 384ms/step - loss: 0.9705 - acc: 0.6803 - val_loss: 1.0435 - val_acc: 0.6557\n",
      "616/616 [==============================] - 237s 384ms/step - loss: 0.9705 - acc: 0.6803 - val_loss: 1.0435 - val_acc: 0.6557\n",
      "Epoch 21/50\n",
      "Epoch 21/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.9304 - acc: 0.6902\n",
      "Epoch 00021: val_acc improved from 0.65567 to 0.66326, saving model to ./drive/My Drive/food_11_weights/resnet50-21-0.66.hdf5\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.65567 to 0.66326, saving model to ./drive/My Drive/food_11_weights/resnet50-21-0.66.hdf5\n",
      "616/616 [==============================] - 237s 385ms/step - loss: 0.9304 - acc: 0.6902 - val_loss: 1.0352 - val_acc: 0.6633\n",
      "616/616 [==============================] - 237s 385ms/step - loss: 0.9304 - acc: 0.6902 - val_loss: 1.0352 - val_acc: 0.6633\n",
      "Epoch 22/50\n",
      "Epoch 22/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.8969 - acc: 0.7070\n",
      "Epoch 00022: val_acc improved from 0.66326 to 0.67845, saving model to ./drive/My Drive/food_11_weights/resnet50-22-0.68.hdf5\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.66326 to 0.67845, saving model to ./drive/My Drive/food_11_weights/resnet50-22-0.68.hdf5\n",
      "616/616 [==============================] - 238s 387ms/step - loss: 0.8969 - acc: 0.7070 - val_loss: 0.9876 - val_acc: 0.6784\n",
      "616/616 [==============================] - 238s 387ms/step - loss: 0.8969 - acc: 0.7070 - val_loss: 0.9876 - val_acc: 0.6784\n",
      "Epoch 23/50\n",
      "Epoch 23/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.8638 - acc: 0.7202\n",
      "Epoch 00023: val_acc did not improve from 0.67845\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 0.8638 - acc: 0.7202 - val_loss: 1.1881 - val_acc: 0.6373\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.67845\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 0.8638 - acc: 0.7202 - val_loss: 1.1881 - val_acc: 0.6373\n",
      "Epoch 24/50\n",
      "Epoch 24/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.8691 - acc: 0.7152\n",
      "Epoch 00024: val_acc did not improve from 0.67845\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.8691 - acc: 0.7152 - val_loss: 1.0826 - val_acc: 0.6489\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.67845\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.8691 - acc: 0.7152 - val_loss: 1.0826 - val_acc: 0.6489\n",
      "Epoch 25/50\n",
      "Epoch 25/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.8384 - acc: 0.7288\n",
      "Epoch 00025: val_acc did not improve from 0.67845\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 0.8384 - acc: 0.7288 - val_loss: 1.4498 - val_acc: 0.5610\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.67845\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 0.8384 - acc: 0.7288 - val_loss: 1.4498 - val_acc: 0.5610\n",
      "Epoch 26/50\n",
      "Epoch 26/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.8073 - acc: 0.7398\n",
      "Epoch 00026: val_acc improved from 0.67845 to 0.69509, saving model to ./drive/My Drive/food_11_weights/resnet50-26-0.70.hdf5\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.67845 to 0.69509, saving model to ./drive/My Drive/food_11_weights/resnet50-26-0.70.hdf5\n",
      "616/616 [==============================] - 236s 382ms/step - loss: 0.8073 - acc: 0.7398 - val_loss: 0.9736 - val_acc: 0.6951\n",
      "616/616 [==============================] - 236s 382ms/step - loss: 0.8073 - acc: 0.7398 - val_loss: 0.9736 - val_acc: 0.6951\n",
      "Epoch 27/50\n",
      "Epoch 27/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.7820 - acc: 0.7481\n",
      "Epoch 00027: val_acc did not improve from 0.69509\n",
      "616/616 [==============================] - 237s 385ms/step - loss: 0.7820 - acc: 0.7481 - val_loss: 1.2455 - val_acc: 0.6323\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.69509\n",
      "616/616 [==============================] - 237s 385ms/step - loss: 0.7820 - acc: 0.7481 - val_loss: 1.2455 - val_acc: 0.6323\n",
      "Epoch 28/50\n",
      "Epoch 28/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.7424 - acc: 0.7590\n",
      "Epoch 00028: val_acc improved from 0.69509 to 0.71583, saving model to ./drive/My Drive/food_11_weights/resnet50-28-0.72.hdf5\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.69509 to 0.71583, saving model to ./drive/My Drive/food_11_weights/resnet50-28-0.72.hdf5\n",
      "616/616 [==============================] - 234s 381ms/step - loss: 0.7424 - acc: 0.7590 - val_loss: 0.9091 - val_acc: 0.7158\n",
      "616/616 [==============================] - 234s 381ms/step - loss: 0.7424 - acc: 0.7590 - val_loss: 0.9091 - val_acc: 0.7158\n",
      "Epoch 29/50\n",
      "Epoch 29/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.7362 - acc: 0.7580\n",
      "Epoch 00029: val_acc improved from 0.71583 to 0.73481, saving model to ./drive/My Drive/food_11_weights/resnet50-29-0.73.hdf5\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.71583 to 0.73481, saving model to ./drive/My Drive/food_11_weights/resnet50-29-0.73.hdf5\n",
      "616/616 [==============================] - 235s 382ms/step - loss: 0.7362 - acc: 0.7580 - val_loss: 0.8406 - val_acc: 0.7348\n",
      "616/616 [==============================] - 235s 382ms/step - loss: 0.7362 - acc: 0.7580 - val_loss: 0.8406 - val_acc: 0.7348\n",
      "Epoch 30/50\n",
      "Epoch 30/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.7373 - acc: 0.7586\n",
      "Epoch 00030: val_acc did not improve from 0.73481\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 0.7373 - acc: 0.7586 - val_loss: 0.9051 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.73481\n",
      "616/616 [==============================] - 233s 379ms/step - loss: 0.7373 - acc: 0.7586 - val_loss: 0.9051 - val_acc: 0.6936\n",
      "Epoch 31/50\n",
      "Epoch 31/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.7139 - acc: 0.7687\n",
      "Epoch 00031: val_acc did not improve from 0.73481\n",
      "616/616 [==============================] - 234s 379ms/step - loss: 0.7139 - acc: 0.7687 - val_loss: 1.0757 - val_acc: 0.7021\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.73481\n",
      "616/616 [==============================] - 234s 379ms/step - loss: 0.7139 - acc: 0.7687 - val_loss: 1.0757 - val_acc: 0.7021\n",
      "Epoch 32/50\n",
      "Epoch 32/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.7066 - acc: 0.7675\n",
      "Epoch 00032: val_acc improved from 0.73481 to 0.73657, saving model to ./drive/My Drive/food_11_weights/resnet50-32-0.74.hdf5\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.73481 to 0.73657, saving model to ./drive/My Drive/food_11_weights/resnet50-32-0.74.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 0.7066 - acc: 0.7675 - val_loss: 0.8555 - val_acc: 0.7366\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 0.7066 - acc: 0.7675 - val_loss: 0.8555 - val_acc: 0.7366\n",
      "Epoch 33/50\n",
      "Epoch 33/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.6911 - acc: 0.7741\n",
      "Epoch 00033: val_acc did not improve from 0.73657\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6911 - acc: 0.7741 - val_loss: 0.9987 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.73657\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6911 - acc: 0.7741 - val_loss: 0.9987 - val_acc: 0.6840\n",
      "Epoch 34/50\n",
      "Epoch 34/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.6644 - acc: 0.7806\n",
      "Epoch 00034: val_acc improved from 0.73657 to 0.74825, saving model to ./drive/My Drive/food_11_weights/resnet50-34-0.75.hdf5\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.73657 to 0.74825, saving model to ./drive/My Drive/food_11_weights/resnet50-34-0.75.hdf5\n",
      "616/616 [==============================] - 235s 382ms/step - loss: 0.6644 - acc: 0.7806 - val_loss: 0.7823 - val_acc: 0.7482\n",
      "616/616 [==============================] - 235s 382ms/step - loss: 0.6644 - acc: 0.7806 - val_loss: 0.7823 - val_acc: 0.7482\n",
      "Epoch 35/50\n",
      "Epoch 35/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.6771 - acc: 0.7800\n",
      "Epoch 00035: val_acc did not improve from 0.74825\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6771 - acc: 0.7800 - val_loss: 0.8897 - val_acc: 0.7196\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.74825\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6771 - acc: 0.7800 - val_loss: 0.8897 - val_acc: 0.7196\n",
      "Epoch 36/50\n",
      "Epoch 36/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.6468 - acc: 0.7886\n",
      "Epoch 00036: val_acc did not improve from 0.74825\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6468 - acc: 0.7886 - val_loss: 1.0378 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.74825\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6468 - acc: 0.7886 - val_loss: 1.0378 - val_acc: 0.7030\n",
      "Epoch 37/50\n",
      "Epoch 37/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.6515 - acc: 0.7897\n",
      "Epoch 00037: val_acc did not improve from 0.74825\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6515 - acc: 0.7897 - val_loss: 0.8822 - val_acc: 0.7304\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.74825\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6515 - acc: 0.7897 - val_loss: 0.8822 - val_acc: 0.7304\n",
      "Epoch 38/50\n",
      "Epoch 38/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.6268 - acc: 0.7937\n",
      "Epoch 00038: val_acc improved from 0.74825 to 0.75613, saving model to ./drive/My Drive/food_11_weights/resnet50-38-0.76.hdf5\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.74825 to 0.75613, saving model to ./drive/My Drive/food_11_weights/resnet50-38-0.76.hdf5\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 0.6268 - acc: 0.7937 - val_loss: 0.8036 - val_acc: 0.7561\n",
      "616/616 [==============================] - 236s 383ms/step - loss: 0.6268 - acc: 0.7937 - val_loss: 0.8036 - val_acc: 0.7561\n",
      "Epoch 39/50\n",
      "Epoch 39/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.6091 - acc: 0.7992\n",
      "Epoch 00039: val_acc did not improve from 0.75613\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6091 - acc: 0.7992 - val_loss: 0.8951 - val_acc: 0.7199\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.75613\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.6091 - acc: 0.7992 - val_loss: 0.8951 - val_acc: 0.7199\n",
      "Epoch 40/50\n",
      "Epoch 40/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5953 - acc: 0.8050\n",
      "Epoch 00040: val_acc did not improve from 0.75613\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5953 - acc: 0.8050 - val_loss: 1.2046 - val_acc: 0.6916\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.75613\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5953 - acc: 0.8050 - val_loss: 1.2046 - val_acc: 0.6916\n",
      "Epoch 41/50\n",
      "Epoch 41/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5823 - acc: 0.8197\n",
      "Epoch 00041: val_acc did not improve from 0.75613\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5823 - acc: 0.8197 - val_loss: 0.7817 - val_acc: 0.7532\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.75613\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5823 - acc: 0.8197 - val_loss: 0.7817 - val_acc: 0.7532\n",
      "Epoch 42/50\n",
      "Epoch 42/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5805 - acc: 0.8137\n",
      "Epoch 00042: val_acc improved from 0.75613 to 0.76577, saving model to ./drive/My Drive/food_11_weights/resnet50-42-0.77.hdf5\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.75613 to 0.76577, saving model to ./drive/My Drive/food_11_weights/resnet50-42-0.77.hdf5\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 0.5805 - acc: 0.8137 - val_loss: 0.7653 - val_acc: 0.7658\n",
      "616/616 [==============================] - 235s 381ms/step - loss: 0.5805 - acc: 0.8137 - val_loss: 0.7653 - val_acc: 0.7658\n",
      "Epoch 43/50\n",
      "Epoch 43/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5722 - acc: 0.8161\n",
      "Epoch 00043: val_acc improved from 0.76577 to 0.76782, saving model to ./drive/My Drive/food_11_weights/resnet50-43-0.77.hdf5\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.76577 to 0.76782, saving model to ./drive/My Drive/food_11_weights/resnet50-43-0.77.hdf5\n",
      "616/616 [==============================] - 235s 382ms/step - loss: 0.5722 - acc: 0.8161 - val_loss: 0.7503 - val_acc: 0.7678\n",
      "616/616 [==============================] - 235s 382ms/step - loss: 0.5722 - acc: 0.8161 - val_loss: 0.7503 - val_acc: 0.7678\n",
      "Epoch 44/50\n",
      "Epoch 44/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5535 - acc: 0.8243\n",
      "Epoch 00044: val_acc did not improve from 0.76782\n",
      "616/616 [==============================] - 234s 379ms/step - loss: 0.5535 - acc: 0.8243 - val_loss: 1.0039 - val_acc: 0.7041\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.76782\n",
      "616/616 [==============================] - 234s 379ms/step - loss: 0.5535 - acc: 0.8243 - val_loss: 1.0039 - val_acc: 0.7041\n",
      "Epoch 45/50\n",
      "Epoch 45/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5620 - acc: 0.8205\n",
      "Epoch 00045: val_acc did not improve from 0.76782\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5620 - acc: 0.8205 - val_loss: 0.9212 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.76782\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5620 - acc: 0.8205 - val_loss: 0.9212 - val_acc: 0.7100\n",
      "Epoch 46/50\n",
      "Epoch 46/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5382 - acc: 0.8251\n",
      "Epoch 00046: val_acc did not improve from 0.76782\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5382 - acc: 0.8251 - val_loss: 0.9452 - val_acc: 0.7258\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.76782\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5382 - acc: 0.8251 - val_loss: 0.9452 - val_acc: 0.7258\n",
      "Epoch 47/50\n",
      "Epoch 47/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5384 - acc: 0.8323\n",
      "Epoch 00047: val_acc improved from 0.76782 to 0.77366, saving model to ./drive/My Drive/food_11_weights/resnet50-47-0.77.hdf5\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.76782 to 0.77366, saving model to ./drive/My Drive/food_11_weights/resnet50-47-0.77.hdf5\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.5384 - acc: 0.8323 - val_loss: 0.7267 - val_acc: 0.7737\n",
      "616/616 [==============================] - 234s 380ms/step - loss: 0.5384 - acc: 0.8323 - val_loss: 0.7267 - val_acc: 0.7737\n",
      "Epoch 48/50\n",
      "Epoch 48/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5405 - acc: 0.8270\n",
      "Epoch 00048: val_acc did not improve from 0.77366\n",
      "616/616 [==============================] - 234s 379ms/step - loss: 0.5405 - acc: 0.8270 - val_loss: 0.9935 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.77366\n",
      "616/616 [==============================] - 234s 379ms/step - loss: 0.5405 - acc: 0.8270 - val_loss: 0.9935 - val_acc: 0.7234\n",
      "Epoch 49/50\n",
      "Epoch 49/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5185 - acc: 0.8335\n",
      "Epoch 00049: val_acc did not improve from 0.77366\n",
      "616/616 [==============================] - 234s 379ms/step - loss: 0.5185 - acc: 0.8335 - val_loss: 0.8900 - val_acc: 0.7339\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.77366\n",
      "616/616 [==============================] - 234s 379ms/step - loss: 0.5185 - acc: 0.8335 - val_loss: 0.8900 - val_acc: 0.7339\n",
      "Epoch 50/50\n",
      "Epoch 50/50\n",
      "616/616 [==============================] - ETA: 0s - loss: 0.5214 - acc: 0.8354\n",
      "Epoch 00050: val_acc did not improve from 0.77366\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5214 - acc: 0.8354 - val_loss: 0.8262 - val_acc: 0.7445\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.77366\n",
      "616/616 [==============================] - 233s 378ms/step - loss: 0.5214 - acc: 0.8354 - val_loss: 0.8262 - val_acc: 0.7445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2dd0080630>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2dd0080630>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's train the model 5 epochs as it will take a lot of time\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
    "    callbacks=[checkpoint, model_callback],\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "kJxh0GOSkI9q",
    "outputId": "73894236-fc09-418a-b6a7-692ad34ab07a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYey1of0klff"
   },
   "outputs": [],
   "source": [
    "history = model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "UFiiqS0OnYVV",
    "outputId": "823dd3ba-1de0-4ae7-ea91-c68fbdd7c99f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(50), history['acc'])\n",
    "plt.plot(range(50), history['val_acc'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n",
    "\n",
    "It appears that after 40 epochs model started to overfit on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "colab_type": "code",
    "id": "1MURS7pCoHLS",
    "outputId": "3d59c36a-4289-4e63-d450-e3256cc7034d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(50), history['loss'])\n",
    "plt.plot(range(50), history['val_loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "jdNYFySR_6du"
   ],
   "name": "Model training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
